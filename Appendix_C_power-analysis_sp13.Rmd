---
title: "Appendix C: Power analysis for SP13 replication"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Introduction
============

**[ADD: BY-TRIAL DATA; ITEM VARIANCE ESTIMATE FROM PILOT]**

This knitr script executes and reports a power analysis for our replication of
Shebani and Pulvermüller (2013, *Cortex*), henceforth SP13.

Data simulations are based on our re-analysis of the original data as shared by
SP13. Since that data set did not consist of trial-level observations, we do not
have a way to estimate item variability from it. We assume a generative model
for the simulations with subjects as the only random effects factor, including
both by-subject random intercepts and slopes for all the fixed effects (see 
model specification below).

We adopt the following approach for our power analysis, which really is a type
of Bayes factor design analysis (see Schönbrodt and Wagenmakers, 2017, 
*Psychon Bull Rev*):

1. Simulate random data from the statistical model fitted to the original data.
2. Fit two logisic mixed models to the data using `lme4`, one that includes the
   interaction of interest and another that does not.
3. Compute a Bayes factor for the two models based on the Bayesian information
   criterion (BIC) (see 
   [this link](https://rpubs.com/lindeloev/bayes_factors) for the exact approach).
4. Repeat steps 1-3 a large number of times for different sample sizes.

This document complements our manuscript submitted as a Registered Report to
*Cortex*. See end of document for session info, including package versions, etc.
and the manuscript for further context.


Justification of BIC approach
-----------------------------

There is a practical reason we do not run simulations using the fully Bayesian
approach we will use for our main analysis:
It takes roughly 2 hours to run each analysis of a simulated data set using
`brms` and bridge sampling (as implemented in our analysis pipeline, see
[Appendix_E_analysis_pipeline](https://github.com/montero-melis/2019_SP13-replication_reg-report/blob/master/Appendix_E_analysis_pipeline.html)).
If we used this approach to simulate 1000 data sets for six different Ns, it
would take approximately 
$6 \times 1000 \times 2 = 12000$ hours
or a little more than *one year and four months* to run the simulations.
Our approach is a compromise that allows for a good enough estimation of Bayes
factors taking into account the specifics of our design as opposed to 
off-the-shelve R packages like `BFDA` (Schönbrodt & Stefan, 2018).


Setup workspace
===============

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library("knitr")
library("tidyverse")  # ggplot2, dplyr, readr, purrr, etc
library("broom")
library("boot")       # for inv.logit()
library("lme4")
library("tictoc")
```


```{r}
# Load original data from SP13
d <- read_csv("data/SP13_orig-data_total-errors_long-format.csv") %>%
  # keep critical interference conditions only
  filter(movement %in% c("arm_paradi", "leg_paradi"))
# For each experimental cell, the maximum number of errors is 48 (see
# "Appendix_B_reanalysis_original.Rmd" for justification0)
d$n <- 48
```


Fit model to original data
==========================

Contrast coding for factors:

```{r}
# movement condition
d$mv <- factor(d$movement)
contrasts(d$mv) <- contr.sum(2)
colnames(contrasts(d$mv)) <- "Arm_Leg"
contrasts(d$mv)
# word type
d$wt <- factor(d$word_type)
contrasts(d$wt) <- contr.sum(2)
colnames(contrasts(d$wt)) <- "ArmW_LegW"
contrasts(d$wt)
```


Maximal random effect structure
------------------------------

Fit binomial mixed model on original data, with maximal random effect structure:

```{r}
fm_max <- glmer(
  cbind(errors, n - errors) ~ 1 + mv * wt +
    (1 + mv * wt | subject),
  data = d, 
  family = "binomial"
  )
summary(fm_max)
```


Set correlation parameters to zero for all random effects
-----------------------------------------------------

The following code fits a model in which all correlation terms between random
effects are set to zero, following Phillip Alday's recommendation. The problem
is that then the by-subject random variance for the critical interaction is
estimated to be zero. Therefore I don't use this simplified model for the
simulations, but the maximal above.

```{r}
# Simple double-bar syntax doesn't do the trick, so use numeric values from design
# matrix. Based on Reinhold Kliegl's post: https://rpubs.com/Reinhold/391071
head(model.matrix(fm_max), 4)
c_mvA_L <- model.matrix(fm_max)[, 2]
c_wtA_L <- model.matrix(fm_max)[, 3]
c_mv_wt <- model.matrix(fm_max)[, 4]
# Fit using double-bar syntax:
fm_nocorr <- glmer(
  cbind(errors, n - errors) ~ 1 + mv * wt +
    (1 + c_mvA_L + c_wtA_L + c_mv_wt || subject),
  data = d, 
  family = "binomial"
  )
summary(fm_nocorr)
```


Estimates for item-level random variability
-------------------------------

[TAKEN FROM THE PILOT DATA...]



Power simulations
=================

Prepare data generating process
-------------------------------

### Load function

Load the **function** that generates binomial data aggregated by subject
([this one](https://github.com/montero-melis/2019_SP13_design_analysis/blob/master/generate_binom_data_subj-only_fnc.R)).

```{r}
source("generate_data_fnc.R")
```


### Set up simulation parameters

The output from the model fit to the original data serves as input to the function.
We need to put them into the right format:

```{r}
# Fixed effects
# Vector of coefficient means
fixef_means <- summary(fm_max)$coef[, 1]
fixef_means

# Covariance matrix (Sigma); we need to square the SEs to convert them to Variances
fixef_sigma <- diag(summary(fm_max)$coef[, 2] ^ 2)  # we assume uncorrelated diagonal matrix
fixef_sigma

# Random effects by subject:
VarCorr(fm_max)
# The variances of the random effects are the diagonals of the covariance matrix
# Strange syntax, but the first call to diag extracts the diagonal, the second
# transforms it into a matrix with 0s on the off-diagonal:
ranef_sigma_subj <- diag(diag(VarCorr(fm_max)$subject))
ranef_sigma_subj
```

An estimate for random effects by item we take from our pilot data (see
[here](https://github.com/montero-melis/2018_replication_sheb-pulv2013/blob/master/1806_pilot_analysis/item-variance_estimates.R)).


```{r}
# We don't have estimates for by-item random slope for movement; we will assume
# it to be the same as the by-subject random variability for the critical
# interaction, which probably is an overestimate but will make our power
# estimates more conservative
ranef_sigma_item <- diag(c(0.65, 0.06)) ^ 2  # square to obtain variances
ranef_sigma_item
```


### Example simulation

We can now call the `simulate_binom` function to generate data:

```{r, message = FALSE}
sim_ex <- simulate_binom(
  Nsubj = 2,
  Nitem = 8,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item
  )
sim_ex
```

If we set `full_output = TRUE`, the output is a list that contains additional
information about the fixed and random effects in the simulation:


```{r, message = FALSE}
simulate_binom(
  Nsubj = 2,
  Nitem = 8,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item,
  full_output = TRUE
  )
```


Functions to analyze simulations
--------------------------------

### Basic function

```{r}
analyze_simulation <- function(df, print_model_summaries = FALSE) {

  # Get the coding scheme right:
  contrasts(df$movement)  <- contr.sum(2)
  contrasts(df$word_type) <- contr.sum(2)
  # function to catch convergence issues
  converge <- function (fm) {
    message <- summary(fm)$optinfo$conv$lme4$messages
    if( is.null(message) ) { "" } else { message }
  }

  # Fit models with maximal random effects:
  # with critical interaction
  fm_max_full <-  glmer(
    Error ~ movement * word_type +
      (1 | subject) +
      (1 | item),
      # (1 + movement * word_type | subject) +
      # (1 + movement | item),
    data = df, family = "binomial"
  )
  # Without fixef interaction term:
  fm_max_null <- update(fm_max_full, formula = ~ . - movement : word_type)

  # Sanity check
  if (print_model_summaries) {
    print(summary(fm_max_full))
    print(summary(fm_max_null))
  }
  
  # Put fixed effect model coefficients into one data frame
  model_info <- bind_rows(
    unnest(tidy(fm_max_full )%>% filter(group == "fixed")) %>%
      mutate(model = "full", convergence = converge(fm_max_full)),
    unnest(tidy(fm_max_null )%>% filter(group == "fixed")) %>% 
      mutate(
        model = "null", convergence = converge(fm_max_null))
    ) %>%
  # Now add more concise info (redundantly repeated across rows, can be filtered
  # out later):
    mutate(
      BIC_full = BIC(fm_max_full),
      BIC_null = BIC(fm_max_null),
      BF_BIC = exp( (BIC(fm_max_null) - BIC(fm_max_full) ) / 2),
      conv_max_full = converge(fm_max_full),
      conv_max_null = converge(fm_max_null)
      ) %>%
    select(-group)
  model_info
}
```


### Example

The output is a one-row data frame with information about the analysis:

```{r, message=FALSE, warning=FALSE}
sim_ex <-  simulate_binom(
  Nsubj = 20,
  Nitem = 40,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item,
  )
tictoc::tic()
an_ex <- analyze_simulation(sim_ex)
tictoc::toc()
an_ex
```


If called with `print_model_summaries = TRUE` it also prints the model summaries
to screen.

```{r, message=FALSE, warning=FALSE}
# analyze_simulation(sim_ex, print_model_summaries = TRUE)
```


### Function to analyze many data sets

```{r}
# Function to analyze many data sets, called with pmap
sim_many <- function(rseed, sim_id, ...) {
  set.seed(rseed)
  df <- simulate_binom(...)
  result <- analyze_simulation(df)
  result$sim_id <- sim_id
  result
}
```



### Run the simulations (generate and analyze data sets)

Number of simulations for each N:

```{r}
nb_sims <- 5  # number of simulations per N
```


Data frame of simulation parameters called with `purrr::pmap`

```{r}
params <- tibble(Nsubj = c(50, 100))
params <- params[rep(1 : nrow(params), each = nb_sims), ]
params$rseed <- sample.int(10 ^ 9, size = nrow(params))
params$sim_id <- seq_len(nrow(params))
head(params, 4)
tail(params, 4)
```

Run the simulations:

```{r, message=FALSE, warning=FALSE}
tictoc::tic()
mysims <- pmap(
  .l = params,
  .f = sim_many,
  # fixed parameters (for clarity, comment out the ones we pass through params)
  # Nsubj =,
  Nitem = 104,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item
  ) %>%
  bind_rows()
tictoc::toc()
```

```{r}
# Merge back the info about the parameters that generated each simulation.
mysims <- left_join(mysims, params) %>%
  # rearrange columns
  select(sim_id : rseed, term : conv_max_null)
head(mysims)
head(mysims) %>% kable
```

Save results to disk

```{r}
write_csv(mysims, "sims_etc/power_simulation_results.csv")
```


Analyze results
---------------

### Shape of data frame with results

The data frame (tibble) contains a lot of information about the model fitting.
Mainly it consists of two sets of output:

1) The BIC of the models and corresponding BF_BIC:

```{r}
sims_BIC <- mysims %>%
  select(sim_id : rseed, BIC_full : conv_max_null) %>%
  unique() %>%
  mutate(any_conv_fail = "" != paste(conv_max_full, conv_max_null, sep = ""))
sims_BIC %>% head() %>% kable()
```

2) The fixed effect coefficient estimates of each model (in long format):

```{r}
sims_coef <- mysims %>%
  select(sim_id : convergence) %>%
  unique() 
sims_coef %>% head() %>% kable()
```



### BF_BIC

Summary of results

```{r}
by(sims_BIC$BF_BIC, with(sims_BIC, list(Nsubj, any_conv_fail)), summary)
```


```{r}
ggplot(sims_BIC, aes(x = log(BF_BIC))) + 
  geom_density() +
  facet_grid(any_conv_fail ~ Nsubj)
```






Conclusion (Revise this!!!)
==========

Our proposed design with $N_{min}=60$ and $N_{max}=96$ (step size = 12) and the
evidence threshold set at $BF_{10} > 6$ or $BF_{01} > 6$ will largely suffice to
guarantee high power (>90%) if the effect was as strong as reported in the
original study. 
Taking into account, however, that a) our re-analysis of the original data suggests
that the effect size might have been severely over-estimated, and b) the
original ANOVA-based analysis seem inappropriate for the data at hand, we have
chosen a design that will also guarantee  a high probability of compelling
evidence using an improved analysis method and with a small-to-medium effect size.


Session info
============

```{r}
sessionInfo()
```
